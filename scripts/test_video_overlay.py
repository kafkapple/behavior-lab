"""Test video overlay pipeline with MABe22 mouse triplet data.

Downloads video data if not present, matches keypoints to video frames,
and generates overlay GIFs for visual inspection.

Usage:
    python scripts/test_video_overlay.py [--n-samples 3] [--n-frames 150]
"""
from __future__ import annotations

import argparse
import sys
import zipfile
from pathlib import Path

import numpy as np

# Add src to path
ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT / "src"))

from behavior_lab.core.skeleton import get_skeleton
from behavior_lab.visualization.video_overlay import (
    overlay_keypoints_on_video,
    overlay_keypoints_on_frame_array,
)
from behavior_lab.visualization.html_report import image_to_base64

DATA_DIR = ROOT / "data" / "raw" / "mabe22"
VIDEO_DIR = DATA_DIR / "videos"
VIDEO_ZIP = VIDEO_DIR / "mouse_userTrain_videos_resized_224.zip"
OUTPUT_DIR = ROOT / "outputs" / "video_overlay"


def extract_videos(zip_path: Path, extract_dir: Path, max_extract: int = 5) -> list[Path]:
    """Extract a few sample videos from the ZIP for testing."""
    extract_dir.mkdir(parents=True, exist_ok=True)

    with zipfile.ZipFile(zip_path, "r") as zf:
        video_names = [n for n in zf.namelist() if n.endswith(".avi") or n.endswith(".mp4")]
        print(f"  ZIP contains {len(video_names)} video files")

        extracted = []
        for name in video_names[:max_extract]:
            out_path = extract_dir / Path(name).name
            if not out_path.exists():
                with zf.open(name) as src, open(out_path, "wb") as dst:
                    dst.write(src.read())
            extracted.append(out_path)
            print(f"  Extracted: {out_path.name}")

    return extracted


def load_raw_keypoints(data_path: Path) -> dict:
    """Load raw MABe22 .npy data with sequence IDs."""
    data = np.load(data_path, allow_pickle=True).item()
    sequences = data.get("sequences", {})
    return sequences


def match_video_to_keypoints(
    video_paths: list[Path],
    raw_sequences: dict,
) -> list[tuple[Path, np.ndarray, str]]:
    """Match video files to keypoint sequences by sequence ID.

    Video filenames are expected to contain or match the sequence ID.
    Returns list of (video_path, keypoints, seq_id) tuples.
    """
    seq_ids = list(raw_sequences.keys())
    matches = []

    for vp in video_paths:
        stem = vp.stem  # filename without extension
        # Try exact match first
        if stem in raw_sequences:
            kp = np.array(raw_sequences[stem]["keypoints"])  # (T, 3, 12, 2)
            matches.append((vp, kp, stem))
            continue

        # Try partial match (video name might have prefix/suffix)
        for sid in seq_ids:
            if sid in stem or stem in sid:
                kp = np.array(raw_sequences[sid]["keypoints"])
                matches.append((vp, kp, sid))
                break

    return matches


def reshape_keypoints_for_overlay(kp: np.ndarray) -> np.ndarray:
    """Reshape (T, 3, 12, 2) -> (T, 36, 2) for multi-person overlay."""
    T, M, J, D = kp.shape
    return kp.reshape(T, M * J, D)


def generate_overlay_report(gif_items: list[dict], output_dir: Path) -> Path:
    """Generate simple HTML report with overlay GIFs."""
    html_path = output_dir / "video_overlay_report.html"

    cards = []
    for item in gif_items:
        cards.append(f"""
        <div style="display:inline-block;margin:10px;text-align:center;">
            <img src="{item['src']}" style="max-width:400px;border:1px solid #ddd;border-radius:8px;">
            <p style="font-size:0.85em;color:#555;">{item['label']}</p>
        </div>
        """)

    html = f"""<!DOCTYPE html>
<html><head><meta charset="utf-8">
<title>MABe22 Video Overlay Test</title>
<style>
body {{ font-family: -apple-system, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; background: #fafafa; }}
h1 {{ color: #2c3e50; }}
.grid {{ display: flex; flex-wrap: wrap; justify-content: center; }}
</style>
</head><body>
<h1>MABe22 Keypoint Overlay Test</h1>
<p>Skeleton keypoints overlaid on original video frames (224x224, 30fps)</p>
<div class="grid">{''.join(cards)}</div>
<p style="color:#999;font-size:0.8em;">Generated by behavior-lab video overlay pipeline</p>
</body></html>"""

    html_path.write_text(html)
    return html_path


def main():
    parser = argparse.ArgumentParser(description="Test MABe22 video overlay")
    parser.add_argument("--n-samples", type=int, default=3, help="Number of sample videos")
    parser.add_argument("--n-frames", type=int, default=150, help="Frames per overlay GIF")
    parser.add_argument("--show-labels", action="store_true", help="Show joint labels")
    args = parser.parse_args()

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    skeleton = get_skeleton("mabe22")
    print(f"Skeleton: {skeleton.name} ({skeleton.num_joints} joints, {skeleton.num_persons} persons)")

    # Step 1: Check video availability
    print("\n[1/4] Checking video data...")
    if not VIDEO_ZIP.exists():
        print(f"  ERROR: Video ZIP not found at {VIDEO_ZIP}")
        print(f"  Download from: https://data.caltech.edu/records/rdsa8-rde65")
        print(f"  Expected: {VIDEO_ZIP}")
        sys.exit(1)

    # Step 2: Extract sample videos
    print("\n[2/4] Extracting sample videos...")
    extract_dir = VIDEO_DIR / "extracted"
    video_paths = extract_videos(VIDEO_ZIP, extract_dir, max_extract=args.n_samples)

    if not video_paths:
        print("  No video files found in ZIP!")
        sys.exit(1)

    # Step 3: Load keypoints and match
    print("\n[3/4] Loading keypoints and matching to videos...")
    raw_path = DATA_DIR / "mouse_user_train.npy"
    if not raw_path.exists():
        print(f"  ERROR: Raw keypoints not found: {raw_path}")
        sys.exit(1)

    raw_sequences = load_raw_keypoints(raw_path)
    print(f"  Loaded {len(raw_sequences)} sequences")

    matches = match_video_to_keypoints(video_paths, raw_sequences)
    print(f"  Matched {len(matches)} video-keypoint pairs")

    if not matches:
        # If no direct match, use first video + first sequence as demo
        print("  No exact matches found. Using first video + first sequence as demo...")
        first_vid = video_paths[0]
        first_sid = list(raw_sequences.keys())[0]
        first_kp = np.array(raw_sequences[first_sid]["keypoints"])
        matches = [(first_vid, first_kp, f"demo_{first_sid[:8]}")]

    # Step 4: Generate overlays
    print(f"\n[4/4] Generating overlay GIFs ({args.n_frames} frames each)...")
    gif_items = []

    for vid_path, kp_raw, seq_id in matches:
        kp = reshape_keypoints_for_overlay(kp_raw)  # (T, 36, 2)
        out_name = f"overlay_{seq_id[:12]}.gif"
        out_path = OUTPUT_DIR / out_name

        print(f"  Processing: {vid_path.name} -> {out_name}")
        print(f"    Video: {vid_path.name}, Keypoints: {kp.shape}")

        try:
            result = overlay_keypoints_on_video(
                video_path=vid_path,
                keypoints=kp,
                skeleton=skeleton,
                output_path=out_path,
                fps=15.0,  # Playback at half speed for clarity
                max_frames=args.n_frames,
                joint_radius=3,
                limb_thickness=2,
                show_labels=args.show_labels,
                opacity=0.9,
                output_format="gif",
            )
            print(f"    Saved: {result} ({result.stat().st_size / 1024:.0f} KB)")

            gif_items.append({
                "label": f"Seq: {seq_id[:16]}... ({kp.shape[0]} total frames)",
                "src": image_to_base64(result),
            })
        except Exception as e:
            print(f"    ERROR: {e}")
            import traceback
            traceback.print_exc()

    # Generate HTML report
    if gif_items:
        report_path = generate_overlay_report(gif_items, OUTPUT_DIR)
        print(f"\nReport: {report_path}")
        print(f"GIFs: {len(gif_items)} generated in {OUTPUT_DIR}")
    else:
        print("\nNo overlays generated.")

    print("\nDone!")


if __name__ == "__main__":
    main()
